# Data
dataset: 'trec'
val_split_ratio: 0.2 # validation set split ratio (default: 0.2)
pre_word_emb_file: '/home/cheny39/Research/Resource/glove-vectors/glove.840B.300d.txt' # path to the pretrained word embedding file
save_model_path: 'text_clf_ckpt'


# Graph construction
graph_type: # 'node_emb' # graph construction type ('dependency', 'constituency', 'ie', 'node_emb', 'node_emb_refined')
      - 'node_emb'

# Dynamic graph construction
init_graph_type: null # initial graph construction type ('line', 'dependency', 'constituency', 'ie')
gl_metric_type: 'weighted_cosine' # similarity metric type for dynamic graph construction ('weighted_cosine', 'attention', 'rbf_kernel', 'cosine')
gl_epsilon: # null # epsilon for graph sparsification
      # - 0.8
      # - 0.7
      # - 0.6
      - 0.5
      - 0.4
gl_top_k: null # top k for graph sparsification
gl_num_heads: # 1 # num of heads for dynamic graph construction
      # - 1
      - 2
gl_num_hidden: 300 # number of hidden units for dynamic graph construction
gl_smoothness_ratio: null # smoothness ratio for graph regularization loss
gl_sparsity_ratio: null # sparsity ratio for graph regularization loss
gl_connectivity_ratio: null # connectivity ratio for graph regularization loss
init_adj_alpha: null # alpha ratio for combining initial graph adjacency matrix


# Graph embedding construction
word_dropout: # 0.4 # word embedding dropout
      # - 0.2
      # - 0.3
      - 0.4
      # - 0.5
rnn_dropout: # 0.1 # RNN dropout
      # - 0.
      - 0.1
      # - 0.2
      # - 0.3
no_fix_word_emb: false # Not fix pretrained word embeddings (default: false)
node_edge_emb_strategy: 'mean' # node edge embedding strategy for graph embedding construction ('mean', 'lstm', 'gru', 'bilstm' and 'bigru')
seq_info_encode_strategy: 'bilstm' # sequence info encoding strategy for graph embedding construction ('none', 'lstm', 'gru', 'bilstm' and 'bigru')


# GNN
gnn: #
      - 'graphsage'
gnn_direction_option: # 'bi_fuse' # GNN direction type ('undirected', 'bi_sep', 'bi_fuse')
      - 'bi_sep'
gnn_num_layers: # 1 # 1 # number of GNN layers
      - 1
num_hidden: 300 # number of hidden units
graph_pooling: 'avg_pool' # graph pooling ('avg_pool', 'max_pool')
max_pool_linear_proj: false # use linear projectioni for max pooling
gnn_dropout: # 0.3 # 0.3 # GNN input feature dropout
      - 0.3

# GAT
gat_attn_dropout: null # GAT attention dropout
gat_negative_slope: null # the negative slope of leaky relu
gat_num_heads: null # number of hidden attention heads
gat_num_out_heads: null # number of output attention heads
gat_residual: false # use gat_residual connection
# GraphSAGE
graphsage_aggreagte_type: 'mean' # graphsage aggreagte type ('mean', 'gcn', 'pool', 'lstm')


# Training
seed: 1234
batch_size: 50 # batch size
epochs: 500 # number of maximal training epochs
patience: 10
lr: # 0.001 # learning rate
      - 0.001
      # - 0.002
      # - 0.0005
lr_patience: 2
lr_reduce_factor: 0.5
num_workers: 0 # number of data loader workers


gpu: 3
no_cuda: false

# gl_epsilon 0.8, gl_num_heads 1: 0.926
# gl_epsilon 0.6, gl_num_heads 2: 0.932
