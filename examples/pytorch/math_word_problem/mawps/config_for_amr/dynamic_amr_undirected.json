{
    "config_path": "examples/pytorch/math_word_problem/mawps/config_for_amr/semantic_parsing_with_tree_decoder_amr.yaml",
    "checkpoint_args.checkpoint_name": "node_emb_sage_undirected.pt",
    "checkpoint_args.out_dir": "examples/pytorch/math_word_problem/mawps/config_for_amr/save",
    "env_args.gpuid": 0,
    "training_args.batch_size": 20,
    "training_args.max_epochs": 150,
    "model_args.graph_construction_args.graph_construction_share.root_dir": "examples/pytorch/math_word_problem/mawps/mawps_data",
    "inference_args.inference_data_dir": "examples/pytorch/math_word_problem/mawps/mawps_data_for_inference",
    "model_args.decoder_args.rnn_decoder_share.dropout": 0.3,
    "model_args.decoder_args.rnn_decoder_private.max_decoder_step": 35,
    "model_args.decoder_args.rnn_decoder_private.max_tree_depth": 8,
    "preprocessing_args.pretrained_word_emb_name": "6B",
    "model_args.graph_construction_name": "amr",
    "model_args.graph_construction_args.graph_construction_share.topology_subdir": "AMRGraphForRGCN",
    "model_args.graph_initialization_args.embedding_style.single_token_item": false,
    "model_args.graph_initialization_args.embedding_style.emb_strategy": "w2v_bilstm_amr_pos"
    }
    